{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.quantrocket.com\"><img alt=\"QuantRocket logo\" src=\"https://www.quantrocket.com/assets/img/notebook-header-logo.png\"></a><br>\n",
    "<a href=\"https://www.quantrocket.com/disclaimer/\">Disclaimer</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "[Pipeline Tutorial](Introduction.ipynb) › Lesson 4: Factors\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factors\n",
    "A factor is a function from an asset and a moment in time to a number.\n",
    "```\n",
    "F(asset, timestamp) -> float\n",
    "```\n",
    "In Pipeline, Factors are the most commonly-used term, representing the result of any computation producing a numerical result. Factors require a column of data and a window length as input.\n",
    "\n",
    "The simplest factors in Pipeline are built-in Factors. Built-in Factors are pre-built to perform common computations. As a first example, let's make a factor to compute the average close price over the last 10 days. We can use the `SimpleMovingAverage` built-in factor which computes the average value of the input data (close price) over the specified window length (10 days). To do this, we need to import our built-in `SimpleMovingAverage` factor and the `EquityPricing` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New from the last lesson, import the EquityPricing dataset.\n",
    "from zipline.pipeline import Pipeline, EquityPricing\n",
    "from zipline.research import run_pipeline\n",
    "\n",
    "# New from the last lesson, import the built-in SimpleMovingAverage factor.\n",
    "from zipline.pipeline.factors import SimpleMovingAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the full list of built-in factors, click on the `factors` module in the above import statement then press Control, or see the [API Reference](https://www.quantrocket.com/docs/api/#built-in-factors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Factor\n",
    "Let's go back to our `make_pipeline` function from the previous lesson and instantiate a `SimpleMovingAverage` factor. To create a `SimpleMovingAverage` factor, we can call the `SimpleMovingAverage` constructor with two arguments: inputs, which must be a list of `BoundColumn` objects, and window_length, which must be an integer indicating how many days worth of data our moving average calculation should receive. (We'll discuss `BoundColumn` in more depth later; for now we just need to know that a `BoundColumn` is an object indicating what kind of data should be passed to our Factor.).\n",
    "\n",
    "The following line creates a `Factor` for computing the 10-day mean close price of securities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_close_10 = SimpleMovingAverage(inputs=EquityPricing.close, window_length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that creating the factor does not actually perform a computation. Creating a factor is like defining the function. To perform a computation, we need to add the factor to our pipeline and run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Factor to a Pipeline\n",
    "\n",
    "Let's update our original empty pipeline to make it compute our new moving average factor. To start, let's move our factor instantiation into `make_pipeline`. Next, we can tell our pipeline to compute our factor by passing it a `columns` argument, which should be a dictionary mapping column names to factors, filters, or classifiers. Our updated `make_pipeline` function should look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    \n",
    "    mean_close_10 = SimpleMovingAverage(inputs=EquityPricing.close, window_length=10)\n",
    "    \n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            '10_day_mean_close': mean_close_10\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what this looks like, let's make our pipeline, run it, and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>10_day_mean_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>asset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">2010-01-05</th>\n",
       "      <th>Equity(FIBBG000C2V3D6 [A])</th>\n",
       "      <td>30.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(QI000000004076 [AABA])</th>\n",
       "      <td>16.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000BZWHH8 [AACC])</th>\n",
       "      <td>6.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000V2S3P6 [AACG])</th>\n",
       "      <td>4.501444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000M7KQ09 [AAI])</th>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG011MC2100 [AATC])</th>\n",
       "      <td>11.980500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000GDBDH4 [BDG])</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000008NR0 [ISM])</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000GZ24W8 [PEM])</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000BB5S87 [HCH])</th>\n",
       "      <td>106.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7841 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          10_day_mean_close\n",
       "date       asset                                           \n",
       "2010-01-05 Equity(FIBBG000C2V3D6 [A])             30.432000\n",
       "           Equity(QI000000004076 [AABA])          16.605000\n",
       "           Equity(FIBBG000BZWHH8 [AACC])           6.434000\n",
       "           Equity(FIBBG000V2S3P6 [AACG])           4.501444\n",
       "           Equity(FIBBG000M7KQ09 [AAI])            5.250000\n",
       "...                                                     ...\n",
       "           Equity(FIBBG011MC2100 [AATC])          11.980500\n",
       "           Equity(FIBBG000GDBDH4 [BDG])                 NaN\n",
       "           Equity(FIBBG000008NR0 [ISM])                 NaN\n",
       "           Equity(FIBBG000GZ24W8 [PEM])                 NaN\n",
       "           Equity(FIBBG000BB5S87 [HCH])          106.570000\n",
       "\n",
       "[7841 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_pipeline(make_pipeline(), start_date='2010-01-05', end_date='2010-01-05')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a column in our pipeline output with the 10-day average close price for all ~8000 securities (display truncated). Note that each row corresponds to the result of our computation for a given security on a given date stored. The `DataFrame` has a MultiIndex where the first level is a datetime representing the date of the computation and the second level is an `Equity` object corresponding to the security.\n",
    "\n",
    "If we run our pipeline over more than one day, the output looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>10_day_mean_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>asset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2010-01-05</th>\n",
       "      <th>Equity(FIBBG000C2V3D6 [A])</th>\n",
       "      <td>30.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(QI000000004076 [AABA])</th>\n",
       "      <td>16.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000BZWHH8 [AACC])</th>\n",
       "      <td>6.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000V2S3P6 [AACG])</th>\n",
       "      <td>4.501444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000M7KQ09 [AAI])</th>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2010-01-07</th>\n",
       "      <th>Equity(FIBBG011MC2100 [AATC])</th>\n",
       "      <td>11.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000GDBDH4 [BDG])</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000008NR0 [ISM])</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000GZ24W8 [PEM])</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000BB5S87 [HCH])</th>\n",
       "      <td>109.796667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23534 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          10_day_mean_close\n",
       "date       asset                                           \n",
       "2010-01-05 Equity(FIBBG000C2V3D6 [A])             30.432000\n",
       "           Equity(QI000000004076 [AABA])          16.605000\n",
       "           Equity(FIBBG000BZWHH8 [AACC])           6.434000\n",
       "           Equity(FIBBG000V2S3P6 [AACG])           4.501444\n",
       "           Equity(FIBBG000M7KQ09 [AAI])            5.250000\n",
       "...                                                     ...\n",
       "2010-01-07 Equity(FIBBG011MC2100 [AATC])          11.816000\n",
       "           Equity(FIBBG000GDBDH4 [BDG])                 NaN\n",
       "           Equity(FIBBG000008NR0 [ISM])                 NaN\n",
       "           Equity(FIBBG000GZ24W8 [PEM])                 NaN\n",
       "           Equity(FIBBG000BB5S87 [HCH])          109.796667\n",
       "\n",
       "[23534 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_pipeline(make_pipeline(), start_date='2010-01-05', end_date='2010-01-07')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: factors can also be added to an existing `Pipeline` instance using the `Pipeline.add` method. Using `add` looks something like this:\n",
    "\n",
    "```python\n",
    "my_pipe = Pipeline()\n",
    "f1 = SomeFactor(...)\n",
    "my_pipe.add(f1, 'f1')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latest\n",
    "The most commonly used built-in `Factor` is `Latest`. The `Latest` factor gets the most recent value of a given data column. This factor is common enough that it is instantiated differently from other factors. The best way to get the latest value of a data column is by getting its `.latest` attribute. As an example, let's update `make_pipeline` to create a latest close price factor and add it to our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "\n",
    "    mean_close_10 = SimpleMovingAverage(inputs=EquityPricing.close, window_length=10)\n",
    "    latest_close = EquityPricing.close.latest\n",
    "\n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            '10_day_mean_close': mean_close_10,\n",
    "            'latest_close_price': latest_close\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, when we make and run our pipeline again, there are two columns in our output dataframe. One column has the 10-day mean close price of each security, and the other has the latest close price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>10_day_mean_close</th>\n",
       "      <th>latest_close_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>asset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2010-01-05</th>\n",
       "      <th>Equity(FIBBG000C2V3D6 [A])</th>\n",
       "      <td>30.432000</td>\n",
       "      <td>31.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(QI000000004076 [AABA])</th>\n",
       "      <td>16.605000</td>\n",
       "      <td>17.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000BZWHH8 [AACC])</th>\n",
       "      <td>6.434000</td>\n",
       "      <td>7.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000V2S3P6 [AACG])</th>\n",
       "      <td>4.501444</td>\n",
       "      <td>4.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(FIBBG000M7KQ09 [AAI])</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          10_day_mean_close  latest_close_price\n",
       "date       asset                                                               \n",
       "2010-01-05 Equity(FIBBG000C2V3D6 [A])             30.432000              31.300\n",
       "           Equity(QI000000004076 [AABA])          16.605000              17.100\n",
       "           Equity(FIBBG000BZWHH8 [AACC])           6.434000               7.150\n",
       "           Equity(FIBBG000V2S3P6 [AACG])           4.501444               4.702\n",
       "           Equity(FIBBG000M7KQ09 [AAI])            5.250000               5.180"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_pipeline(make_pipeline(), start_date='2010-01-05', end_date='2010-01-05')\n",
    "result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.latest` can sometimes return things other than `Factors`. We'll see examples of other possible return types in later lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Inputs\n",
    "Some factors have default inputs that should never be changed. For example the VWAP built-in factor is always calculated from `EquityPricing.close` and `EquityPricing.volume`. When a factor is always calculated from the same `BoundColumn`, we can call the constructor without specifying `inputs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline.factors import VWAP\n",
    "vwap = VWAP(window_length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Start Date\n",
    "\n",
    "When choosing a `start_date` for `run_pipeline`, there are two gotchas to keep in mind. First, the earliest possible `start_date` you can specify must be one day after the start date of the bundle. This is because the `start_date` you pass to `run_pipeline` indicates the first date you want to include in the pipeline output, and each day's pipeline output is based on the previous day's data. The purpose of this one-day lag is to avoid lookahead bias. Pipeline output tells you what you would have known at the start of each day, based on the previous day's data.\n",
    "\n",
    "The learning bundle starts on 2007-01-03 (the first trading day of 2007), but if we try to run a pipeline that starts on (or before) that date, we'll get an error that tells us to start one day after the bundle start date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "start_date cannot be earlier than 2007-01-04 for this bundle (one session after the bundle start date of 2007-01-03)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2007-01-03\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2007-01-03\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/research/pipeline.py:95\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(pipeline, start_date, end_date, bundle)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_pipeline\u001b[39m(\n\u001b[1;32m     37\u001b[0m     pipeline: Pipeline,\n\u001b[1;32m     38\u001b[0m     start_date: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     39\u001b[0m     end_date: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m     bundle: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    Compute values for pipeline from start_date to end_date, using the specified\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    bundle or the default bundle.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m        factor = run_pipeline(pipeline, '2018-01-01', '2019-02-01', bundle=\"usstock-1min\")\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbundle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/research/pipeline.py:149\u001b[0m, in \u001b[0;36m_run_pipeline\u001b[0;34m(pipeline, start_date, end_date, bundle, mask)\u001b[0m\n\u001b[1;32m    147\u001b[0m second_session \u001b[38;5;241m=\u001b[39m exchange_calendar\u001b[38;5;241m.\u001b[39mnext_session(first_session)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_date \u001b[38;5;241m<\u001b[39m second_session:\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_date cannot be earlier than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msecond_session\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;241m.\u001b[39misoformat()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this bundle (one session after the bundle start date of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_session\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;241m.\u001b[39misoformat()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Roll-forward start_date to valid session\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n",
      "\u001b[0;31mValidationError\u001b[0m: start_date cannot be earlier than 2007-01-04 for this bundle (one session after the bundle start date of 2007-01-03)"
     ]
    }
   ],
   "source": [
    "result = run_pipeline(Pipeline(), start_date='2007-01-03', end_date='2007-01-03')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second gotcha to keep in mind is that the `start_date` you choose must also make allowance for the `window_length` of your factors. The following pipeline includes a 10-day VWAP factor, so if we set the `start_date` to 2007-01-04 (as suggested by the previous error message), we will get a new error (scroll to the bottom of the traceback for the useful error message):    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NoDataOnDate",
     "evalue": "the pipeline definition requires EquityPricing<US>.close::float64 data on 2006-12-18 00:00:00 but no bundle data is available on that date; the cause of this issue is that another pipeline term needs EquityPricing<US>.close::float64 and has a window_length of 10, which necessitates loading 9 extra rows of EquityPricing<US>.close::float64; try setting a later start date so that the maximum window_length of any term doesn't extend further back than the bundle start date. Review the pipeline dependencies below to help determine which terms are causing the problem:\n\n{'dependencies': [{'term': EquityPricing<US>.close::float64,\n                   'used_by': VWAP([EquityPricing.close, EquityPricing.volume], 10)},\n                  {'term': EquityPricing<US>.volume::float64,\n                   'used_by': VWAP([EquityPricing.close, EquityPricing.volume], 10)}],\n 'nodes': [{'extra_rows': 9, 'needed_for': EquityPricing<US>.close::float64},\n           {'extra_rows': 9, 'needed_for': EquityPricing<US>.volume::float64}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32mindex.pyx:598\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1166400000000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:566\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:600\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2006-12-18 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:631\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2006-12-18 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/data/bcolz_daily_bars.py:578\u001b[0m, in \u001b[0;36mBcolzDailyBarReader._load_raw_arrays_date_to_index\u001b[0;34m(self, date)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msessions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:633\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(orig_key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2006-12-18 00:00:00')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoDataOnDate\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/pipeline/engine.py:763\u001b[0m, in \u001b[0;36mSimplePipelineEngine.compute_chunk\u001b[0;34m(self, graph, dates, sids, workspace, refcounts, execution_order, hooks)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 763\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_adjusted_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NoDataOnDate \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/pipeline/loaders/equity_pricing_loader.py:90\u001b[0m, in \u001b[0;36mEquityPricingLoader.load_adjusted_array\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     88\u001b[0m ohlcv_colnames \u001b[38;5;241m=\u001b[39m [c\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m ohlcv_cols]\n\u001b[0;32m---> 90\u001b[0m raw_ohlcv_arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_price_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_raw_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mohlcv_colnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshifted_dates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshifted_dates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43msids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Currency convert raw_arrays in place if necessary. We use shifted\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# dates to load currency conversion rates to make them line up with\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# dates used to fetch prices.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/data/bcolz_daily_bars.py:557\u001b[0m, in \u001b[0;36mBcolzDailyBarReader.load_raw_arrays\u001b[0;34m(self, columns, start_date, end_date, assets)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_raw_arrays\u001b[39m(\u001b[38;5;28mself\u001b[39m, columns, start_date, end_date, assets):\n\u001b[0;32m--> 557\u001b[0m     start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_raw_arrays_date_to_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_raw_arrays_date_to_index(end_date)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/data/bcolz_daily_bars.py:580\u001b[0m, in \u001b[0;36mBcolzDailyBarReader._load_raw_arrays_date_to_index\u001b[0;34m(self, date)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoDataOnDate(date)\n",
      "\u001b[0;31mNoDataOnDate\u001b[0m: 2006-12-18 00:00:00",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoDataOnDate\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m      2\u001b[0m     columns\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvwap\u001b[39m\u001b[38;5;124m\"\u001b[39m: VWAP(window_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      4\u001b[0m     }\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2007-01-04\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2007-01-04\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/research/pipeline.py:95\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(pipeline, start_date, end_date, bundle)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_pipeline\u001b[39m(\n\u001b[1;32m     37\u001b[0m     pipeline: Pipeline,\n\u001b[1;32m     38\u001b[0m     start_date: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     39\u001b[0m     end_date: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m     bundle: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    Compute values for pipeline from start_date to end_date, using the specified\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    bundle or the default bundle.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m        factor = run_pipeline(pipeline, '2018-01-01', '2019-02-01', bundle=\"usstock-1min\")\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbundle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/research/pipeline.py:251\u001b[0m, in \u001b[0;36m_run_pipeline\u001b[0;34m(pipeline, start_date, end_date, bundle, mask)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_chunks:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# Run in 1-years chunks to reduce memory usage\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     chunksize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m252\u001b[39m\n\u001b[0;32m--> 251\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_chunked_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     results \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mrun_pipeline(pipeline, start_date, end_date)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/pipeline/engine.py:350\u001b[0m, in \u001b[0;36mSimplePipelineEngine.run_chunked_pipeline\u001b[0;34m(self, pipeline, start_date, end_date, chunksize, hooks)\u001b[0m\n\u001b[1;32m    348\u001b[0m run_pipeline \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_pipeline_impl, pipeline, hooks\u001b[38;5;241m=\u001b[39mhooks)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hooks\u001b[38;5;241m.\u001b[39mrunning_pipeline(pipeline, start_date, end_date):\n\u001b[0;32m--> 350\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# OPTIMIZATION: Don't make an extra copy in `categorical_df_concat`\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# if we don't have to.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/pipeline/engine.py:350\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    348\u001b[0m run_pipeline \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_pipeline_impl, pipeline, hooks\u001b[38;5;241m=\u001b[39mhooks)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hooks\u001b[38;5;241m.\u001b[39mrunning_pipeline(pipeline, start_date, end_date):\n\u001b[0;32m--> 350\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m [\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m ranges]\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# OPTIMIZATION: Don't make an extra copy in `categorical_df_concat`\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# if we don't have to.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/pipeline/engine.py:440\u001b[0m, in \u001b[0;36mSimplePipelineEngine._run_pipeline_impl\u001b[0;34m(self, pipeline, start_date, end_date, hooks)\u001b[0m\n\u001b[1;32m    434\u001b[0m execution_order \u001b[38;5;241m=\u001b[39m plan\u001b[38;5;241m.\u001b[39mexecution_order(workspace, refcounts)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hooks\u001b[38;5;241m.\u001b[39mcomputing_chunk(execution_order,\n\u001b[1;32m    437\u001b[0m                            start_date,\n\u001b[1;32m    438\u001b[0m                            end_date):\n\u001b[0;32m--> 440\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43msids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefcounts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefcounts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_narrow(\n\u001b[1;32m    451\u001b[0m     plan\u001b[38;5;241m.\u001b[39moutputs,\n\u001b[1;32m    452\u001b[0m     results,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m     sids,\n\u001b[1;32m    456\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/zipline/pipeline/engine.py:777\u001b[0m, in \u001b[0;36mSimplePipelineEngine.compute_chunk\u001b[0;34m(self, graph, dates, sids, workspace, refcounts, execution_order, hooks)\u001b[0m\n\u001b[1;32m    767\u001b[0m         extra_rows \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mextra_rows[term]\n\u001b[1;32m    768\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    769\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe pipeline definition requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mterm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but no bundle data is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    770\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavailable on that date; the cause of this issue is that another pipeline term needs \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe problem:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(graph)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    776\u001b[0m         )\n\u001b[0;32m--> 777\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NoDataOnDate(msg)\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(loaded) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mset\u001b[39m(to_load), (\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloader did not return an AdjustedArray for each column\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    784\u001b[0m     )\n\u001b[1;32m    785\u001b[0m )\n\u001b[1;32m    786\u001b[0m workspace\u001b[38;5;241m.\u001b[39mupdate(loaded)\n",
      "\u001b[0;31mNoDataOnDate\u001b[0m: the pipeline definition requires EquityPricing<US>.close::float64 data on 2006-12-18 00:00:00 but no bundle data is available on that date; the cause of this issue is that another pipeline term needs EquityPricing<US>.close::float64 and has a window_length of 10, which necessitates loading 9 extra rows of EquityPricing<US>.close::float64; try setting a later start date so that the maximum window_length of any term doesn't extend further back than the bundle start date. Review the pipeline dependencies below to help determine which terms are causing the problem:\n\n{'dependencies': [{'term': EquityPricing<US>.close::float64,\n                   'used_by': VWAP([EquityPricing.close, EquityPricing.volume], 10)},\n                  {'term': EquityPricing<US>.volume::float64,\n                   'used_by': VWAP([EquityPricing.close, EquityPricing.volume], 10)}],\n 'nodes': [{'extra_rows': 9, 'needed_for': EquityPricing<US>.close::float64},\n           {'extra_rows': 9, 'needed_for': EquityPricing<US>.volume::float64}]}"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    columns={\n",
    "        \"vwap\": VWAP(window_length=10)\n",
    "    }\n",
    ")\n",
    "\n",
    "result = run_pipeline(pipeline, start_date='2007-01-04', end_date='2007-01-04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error message indicates that we would need data back to 2006-12-18 in order to calculate a 10-day VWAP and produce pipeline output on 2007-01-04 (`window_length` is measured in trading days, not calendar days). The solution is to set a later start date so that the VWAP factor doesn't require data prior to the bundle start date of 2007-01-03. In this example, the earliest possible `start_date` turns out to be 2007-01-18 (14 calendar days, or 10 trading days, after 2007-01-04). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_pipeline(pipeline, start_date='2007-01-18', end_date='2007-01-18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Next Lesson:** [Combining Factors](Lesson05-Combining-Factors.ipynb) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
